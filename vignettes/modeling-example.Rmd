---
title: "A modeling example"
author: "Julien Vollering"
date: "`r Sys.Date()`"
output:
      rmarkdown::html_vignette:
        fig_caption: yes
vignette: >
  %\VignetteIndexEntry{A modeling example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

This short vignette is meant to introduce users to the `MIAmaxent` package by providing a worked example of a distribution modeling exercise. It shows how to use all of the main functions included in `MIAmaxent` in the order of a typical analysis. This vignette does NOT describe the theoretical underpinnings of the package. To learn more about the theory behind `MIAmaxent`, the user is referred to Halvorsen (2013)[^1] and Halvorsen et al. (2015)[^2], as well as other references listed in the documentation of the package. 

>__Help pages for the package and for individual functions in the package can be accessed in R using the help command: `?('MIAmaxent')`.__ 


***


## Data set

The data used for demonstration in this vignette are a set of data that have been used to model the distribution of semi-natural grasslands in Ã˜stfold County, in southeastern Norway. The data set consists of 1059 locations where presence of semi-natural grasslands has been recorded, 13 environmental variables covering the extent of the study area, and 122 locations where the presence or absence of semi-natural grasslands has been recorded, independently of the presence-only records. The extent of the study area is about 4000 square kilometers, and grain of the raster data is 500 meters (0.25 km^2^).

>__The data used in this vignette are included in the package as an example data set, so the code and results shown here can be directly replicated.__  

Before beginning the modeling exercise, it may be useful to see what the data look like in their geographical representation. We can use the `raster` package to plot the 1059 recorded presences on top of one of the environmental variable rasters:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.cap="Presence-only occurrence across the study area"}
library(raster)
EV1 <- raster(list.files(system.file("extdata", "EV_continuous", package = "maxentmodelselectr"), full.names = TRUE)[1])
PO <- read.csv(system.file("extdata", "occurrence_PO.csv", package = "maxentmodelselectr"))

par(mar=c(3.1,3.1,2.1,0.1))
plot(EV1, colNA = 'black', legend=FALSE)
points(PO$POINT_X, PO$POINT_Y, pch = 20, cex = 0.5, col = 'blue')
par(mar=c(5.1,4.1,4.1,2.1))
```

##### readData(...)

The starting point for modeling using `MIAmaxent` is a simple data object that contains occurrence data for the modeled target as well as all of the environmental data. The format of this data object is a data frame with the response variable of the model (occurrence) in the first column, and explanatory variables of the model (environmental variables) in subsequent columns. In generative Maxent modeling, the response variable (RV) is binary, and can be either presence or unknown background. These values are coded as "1" and "NA" respectively in the data object. Explanatory variables (EVs) may be continuous or categorical, and these types are denoted by numeric class and factor class respectively. 

>__The `readData(...)` function transforms data in CSV and ASCII raster file formats into a single data frame which serves as the starting point for modeling.__  

Users of the maxent.jar program are usually accustomed to having their training data in an a different format. Specifically, occurrence data is often in CSV file format, with presences records followed by coordinates, and environmental data in ASCII raster file format. The `readData` function makes it easy to convert these data formats into the data object that is used in `MIAmaxent`. This function extracts values of the environmental variables at presence locations and at a set of randomly selected background locations, and properly formats these into the starting point for modeling. Alternatively, the user can also specify a custom set of background locations by giving these in the CSV file. 

We begin by creating our data object from file. Note that continuous and categorical environmental variables should be placed in separate directories:
```{r}
library(maxentmodelselectr)
grasslandPO <- readData(occurrence = system.file("extdata", "occurrence_PO.csv", package = "maxentmodelselectr"), 
                  contEV = system.file("extdata", "EV_continuous", package = "maxentmodelselectr"),
                  catEV = system.file("extdata", "EV_categorical", package = "maxentmodelselectr"),
                  maxbkg = 20000)

```

>__All functions in `MIAmaxent` produce console output. Therefore it's handy to always assign function output to an object, so that you can manipulate that object further.__  

If we look at the resulting data object we see the response variable (with `r sum(grasslandPO$RV == 1, na.rm = TRUE)` presence and `r sum(is.na(grasslandPO$RV))` background points) along with `r sum(sapply(grasslandPO[,-1], class) == "numeric")` continuous and `r sum(sapply(grasslandPO[,-1], class) == "factor")` categorical explanatory variables:
```{r}
str(grasslandPO)
sum(grasslandPO$RV == 1, na.rm = TRUE)
sum(is.na(grasslandPO$RV))
```

_IMPORTANT: Important considerations for distribution modeling, such as accounting for sampling bias and setting study area extent, are not dealt with in `MIAmaxent`, and must be dealt with beforehand. Good modeling practice requires that these issues be attended to!_


***


## Occurrence-environment relationships

By its simplest definition, a distribution model examines the relationship between the modeled target and its environment. In this way, distribution modeling follows the long tradition of gradient analysis in ecology[^1]. Therefore, before building an actual model, we should have some idea about what influence the environmental variables have on the occurrence of the target.

##### plotFOP(...)

We can use the `plotFOP` function to create a so-called Frequency of Observed Presence (FOP) plot. An FOP plot shows how commonly the target occurs across the range of the explanatory variable, and makes it possible to recognize patterns in frequency of occurrence. Most often, the relationship between an environmental variable and modeled target is linear or unimodal, but the pattern seen in the FOP plot depends on the range of the EV, which in turn depends on the extent of the study area.

Here we examine FOP plots for 2 of the continuous explanatory variables:
```{r, fig.show='hold'}
teraspifFOP <- plotFOP(grasslandPO, "teraspif")
terslpdgFOP <- plotFOP(grasslandPO, "terslpdg")
```

We can change the appearance of the plot with additional arguments, or access the plot data directly:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.align = "center"}
terslpdgFOP <- plotFOP(grasslandPO, "terslpdg", intervals = 25,  pch=20, cex=1.1, col = "red")
terslpdgFOP$FOPdata
```

Now we examine FOP plots for 1 of the categorical explanatory variables:
```{r, fig.show='hold', fig.width=7, fig.height=4, fig.align = "center"}
geobergFOP <- plotFOP(grasslandPO, 10)
```

We see that geoberg type 4 has the highest rate of observed presence, followed by type 2, and then types 3 and 28. If we look more closely at the data however, we notice also that geoberg type 4 is sampled very rarely, with only `r geobergFOP$FOPdata$n[geobergFOP$FOPdata$level == 4]` locations falling into that category: 
```{r}
geobergFOP
```

>__It is recommended that FOP plots for all explanatory variables be examined before building a model.__

Looking at FOP plots can help the modeler decide which explanatory variables are likely to have greatest explanatory power, and gives an idea of the strength and shape of the relationships between the explanatory and response variables.


***


## Transforming explanatory variables

To fit the many different kinds of relationships between explanatory and response variables, we need to transform the explanatory variables. This means that we create new "derived" variables (DVs) from the original explanatory variables. Another way of thinking about this is to put it in terms of rescaling the explanatory variable; we adjust the scale of the explanatory variable in many different ways in order to check which scaling is most ecologically relevant to the occurrence of the modeled target.

##### deriveVars(...)

The `deriveVars` function produces derived variables from explanatory variables by 7 different transformation types: linear, monotonous, deviation, forward hinge, reverse hinge, threshold, and binary. The first 6 of these are relevant for continuous variables and the binary transformation is relevant only for categorical variables. Different types of transformations can be turned on or off in order to balance model complexity with model fit. 

For the spline-type transformations (forward hinge, reverse hinge, threshold) an endless number of different transformations are possible, so the function produces 20 of each, and then chooses those which explain the most variation in the response variable. This means that 20 models are built and evaluated for each combination of explanatory variable and spline transformation. Therefore, running `deriveVars` with these transformation types turned on may take some time.

Here we produce all types of derived variables from our explanatory variables:
```{r}
grasslandDVs <- deriveVars(grasslandPO, transformtype = c("L", "M", "D", "HF", "HR", "T", "B"))
```

>__Use the `dir` argument to specify the directory to which files will be written in the `deriveVars`, `selectDVforEV`, `selectEV`, and `plotResp` functions.__

The console output of `deriveVars` (which is saved above as `grasslandDVs`) consists of 2 parts:

* data frames of DVs for each EV (named "EVDV")  
* the transformation function used to produce each DV (named "transformations")
In our grasslands analysis, the contents of these two items look like this:
```{r}
summary(grasslandDVs$EVDV) # alternatively: summary(grasslandDVs[[1]])
head(summary(grasslandDVs$transformations)) # alternatively: head(summary(grasslandDVs[[2]]))
length(grasslandDVs$transformations)
```

***

Note that the names of derived variables indicate the type of transformation was used to create them. For example, "terslpdg\_D2" is a deviation-type transformation of terslpdg, where the slope of the deviation is controlled by a parameter value of 2. Meanwhile, "terslpdg\_HR4" is the a reverse hinge transformation, with the knot in the 4th position.

We can check how derived variables relate to the original, untransformed explanatory variable from which they came. Here we look at "terslpdg\_D2" and "terslpdg\_HR4":
```{r, fig.show='hold'}
plot(grasslandPO$terslpdg, grasslandDVs$EVDV$terslpdg$terslpdg_D2, pch = 20)
plot(grasslandPO$terslpdg, grasslandDVs$EVDV$terslpdg$terslpdg_HR4, pch = 20)
```

***

The models used to select spline-type derived variables are written to file and the process of spline selection can be inspected by navigating to the directory to which the files were written (default is the working directory). Inside the "deriveVars" folder are folders for each explanatory variable, inside of which are folders for the spline transformation types. Inside each of these folders are 2 files of particular interest: the "splineselection.csv" file gives the model details for each of the 20 candidate derived variables, while the "Vknotplot.png" file shows the variation explained by the 20 candidate variables. Selected candidates are marked in red. Below is an example of one of the V-knot plots:

![V-knot plot of forward hinge variables derived from terslpdg](figures/Vknotplot.png)


***


## Selecting variables

With derived variables ready, we are ready to begin the process of choosing which variables to include in the model. This is arguably the most critical process in building a model. Following the principle of parsimony, the aim in selecting variables is to explain as much variation in the response variable as efficiently as possible. The greater the number of explanatory or derived variables included in the model, the more variation in the response variable we can explain, but at the cost of model complexity. In the `MIAmaxent` package, the benefit of additional variation explained is weighed against the cost in model complexity using an F-test. Variables are added to the model one by one in a process of forward selection, and each new model is compared to its predecessor. Another term for this process is "nested model comparison". 

Rather than selecting from the full pool of derived variables one by one, `MIAmaxent` performs variable selection in two parts:  

1. First, a group of derived variables is selected separately for each individual explanatory variable. This is done using the `selectDVforEV` function.  
2. Second, the explanatory variables themselves, each represented by a group of derived variables, are selected. This is done using the `selectEV` function. 

>__Variable selection occurs hierarchically: first derived variables within each explanatory variable, then explanatory variables within the full model.__

##### selectDVforEV(...)

The `selectDVforEV` function performs forward selection of individual derived variables (DVs) for each explanatory variable (EV). In other words, the function takes each EV one by one, and narrows the group of DVs produced from that EV (by `deriveVars`) to a group which explains variation in the response variable most efficiently.

The alpha-value specified in the function is used in the F-test during forward selection, and sets the threshold for how much variation a DV must explain to be retained. Lower alpha values signify a more conservative test, such that DVs must explain more variation to be included.  

Here we use `selectDVforEV` on the grassland data set. Note the "[[1]]" following grasslandsDV, which specifies the list of DVs in the `deriveVars` output.
```{r}
grasslandDVselect <- selectDVforEV(grasslandPO, grasslandDVs[[1]], alpha = 0.001)
```

The output of selectDVforEV consists of 2 main parts:  

* the DVs that were selected for each EV (named "selectedDV")  
* the trails of nested models that were built and compared for each explanatory variable during the selection process (named "selection")

We can see that `selectDVforEV` has reduced the number of derived variables by comparing the list of DVs before and after:
```{r}
summary(grasslandDVs$EVDV)
sum(sapply(grasslandDVs$EVDV, length))
summary(grasslandDVselect$selectedDV)
sum(sapply(grasslandDVselect$selectedDV, length))
```
Note also that the number of explanatory variables was reduced from 13 to 10. Explanatory variables for which none of the derived variables explained a significant amount of variance are dropped. 

Here is an example of one of the trails of forward DV selection. Shown is the trail for the "terdem" EV:
```{r}
grasslandDVselect$selection$terdem[, -13]
```
The columns in this data frame represent: the round of variable selection (round), the name of the model per round (model), the names of the derived variables included in the model (DV), the number of variables in the model (m), the training AUC (trainAUC), the Entropy or log loss of the model (Entropy), the fraction of variation explained (FVA), the additional variation explained compared to the best model of the previous round (addedFVA), the degrees of freedom of the explained variance (dfe), the degrees of freedom of the unexplained variance (dfu), and the p-value of the F-test comparing the model to the previous round's best model (Pvalue). The model directory, recorded in column 13, is not shown. 

This table shows, for example, that in the first round of selection, one model was built for each of the 8 derived variables, and that all of these explained enough variation to be retained for the second round of selection. Of all the derived variables produced from "terdem", "terdem\_HR18" explained the most variation in the response variable. Furthermore, "terdem\_HR4" explained enough of the remaining variation to be selected as well (Pvalue < alpha). 

##### selectEV(...)

Part 2 of variable selection using `MIAmaxent` is performed by the `selectEV` function. This function is similar to the `selectDVforEV` function, but instead of selecting parsimonious groups of derived variables to represent each explanatory variable, `selectEV` selects explanatory variables. This proceeds in the same manner as `selectDVforEV`, with nested model comparison using the F-test. Where `selectDVforEV` adds a single DV at a time, `selectEV` adds a single _group of DVs_, representing a single EV, at a time. 

The `selectEV` function also differs from `selectDVforEV` in one other very important way; it includes the option of including interaction terms between selected explanatory variables in the model (`interaction = TRUE`). Interaction terms between variables are useful when one explanatory variable changes the effect of another explanatory variable on the modeled target. In `MIAmaxent` interaction terms are produced by simple multiplication between all pairs of derived variables representing the two interacting explanatory variables. Interaction terms are only allowed between EVs which are both included in the model. 

Here we use `selectEV` on the grassland data set. Note the "[[1]]" following grasslandsDVselect, which specifies the list of selected DVs in the `selectDVforEV` output.
```{r}
grasslandEVselect <- selectEV(grasslandPO, grasslandDVselect[[1]], alpha = 0.001, interaction = TRUE)
```

The output of selectEV consists of 2 main parts:  

* the EVs that were selected (named "selectedEV"), each represented by a group of selected DVs.  
* the trail of nested models that were built and compared during the selection process (named "selection")

Now compare the list of EVs before and after:
```{r}
summary(grasslandDVselect[[1]])
length(grasslandDVselect[[1]])
summary(grasslandEVselect[[1]])
length(grasslandEVselect[[1]])
```
We can see that `selectEV` has reduced the number of explanatory variables to 9, but it has also added new interaction terms between explanatory variables selected for the model.

Here we show the best model of each round in the trail of forward selection of EVs and interaction terms, hiding a few columns for readability:
```{r}
roundbests <- grasslandEVselect$selection[-(1:nrow(grasslandEVselect$selection)),]
for (i in unique(grasslandEVselect$selection$round)) {
  roundbest <- grasslandEVselect[[2]][grasslandEVselect$selection$round == i, ][1,]
  roundbests <- rbind(roundbests, roundbest)
}
roundbests[, -c(3, 6, 10, 11, 13)]
```
The full selection trail is automatically saved as a CSV-format file in the directory specified by the `dir` argument in `selectEV`. It is recommended to open this file (named: "evselection.csv") using spreadsheet software to inspect the trail of forward selection more closely. This allows the user to make an informed decision about what is the best model. 

>__The trail of forward variable selection is automatically written to file (in the specified `dir`), and should be examined using spreadsheet software.__

We can also look at the selection trail in graphical form. For example, we may plot additional variation explained across round number, to see how much better the model fit is for each round of adding a variable:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.align = "center"}
plot(grasslandEVselect$selection$round, grasslandEVselect$selection$addedFVA)
```

For example, we may decide that a simple model with only 5 explanatory variables is best, since rounds 6-13 explain only small amounts of additional variation. Thus, we choose the best model in round 5:
```{r}
grasslandEVselect[[2]][grasslandEVselect$selection$round == 5, ][1, -13]
```
The variables included in this model are: pr_bygall, terslpps15, pca1, lcucor1, and geoberg.


***


## Exploring the model

After building a model by selecting which explanatory variable to include, it is useful to explore what the model actually looks like. A straightforward way to do this is to look at model predictions over a range of explanatory data. This gives the modeler a sense of the relationships that the model has captured between explanatory variables and response variables, and can also help the modeler understand strengths and weaknesses in the model.  

##### plotResp(...)

We can use the `plotResp` function to create a so-called response plot. A response plot graphs model output across the range of one particular explanatory variable. When other variables are excluded from the model entirely, this is called a "single-effect response plot".

Here we examine a single-effect response plot for the most important explanatory variable included in the model chosen above:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.align = "center"}
pr_bygallResp <- plotResp(grasslandPO, grasslandEVselect[[1]], "pr_bygall")
```

To assess how well the relationship between the explanatory variable and the response variable is captured by the model, it can be useful to examine FOP plots and response plots side-by-side:
```{r, fig.show='hold'}
pr_bygallFOP <- plotFOP(grasslandPO, "pr_bygall", intervals=50)
pr_bygallResp <- plotResp(grasslandPO, grasslandEVselect[[1]], "pr_bygall")
```

The values on the y-axes of the plots are not directly comparable, but one can expect that the shape of the response plot curve should mirror, more or less closely, the shape of the FOP plot curve.

Here is the same comparison for one of the categorical variables included in the model:
```{r, fig.show='hold'}
terslpps15FOP <- plotFOP(grasslandPO, "terslpps15")
terslpps15Resp <- plotResp(grasslandPO, grasslandEVselect[[1]], "terslpps15")
```

##### plotResp2(...)

The `plotResp2` function in `MIAmaxent` is very similar to the `plotResp` function in that it is used to produce model response plots. However, `plotResp2` produces "marginal-effect response plots" instead of "single-effect response plots". A marginal-effect response plot graphs model output across the range of one particular explanatory variable _while holding all other variables in the model constant at their mean value_. 

The two response plot functions also work in distinctly different ways, so the input to the functions differs.

Here is the marginal-effect response plot for the same continuous explanatory variable shown above (note that `model` and `transformation` file pathways will normally lead to files in the user-specified directory): 
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.align = "center"}
pr_bygallResp2 <- plotResp2(grasslandPO, "pr_bygall", 
  transformation = grasslandDVs[[2]], 
  model = system.file("extdata", "1.lambdas", package = "maxentmodelselectr"))
```


***

## Using the model

For many modeling applications the ultimate motivation for building a model is to obtain model predictions. Model predictions, or model output, can be used in many different ways: to make predictions about parts of the study area for which there exist no occurrence data, to predict relative probability of occurrence outside the study area, or to predict relative probability of occurrence in the past or future. In other words, any form of spatial or temporal interpolation or extrapolation is possible (although not always recommended!). The only requirement is that the values of the explanatory variables are known for the time or space for which model output is desired. 

##### projectModel(...)

The `projectModel` function in `MIAmaxent` can be used to obtain model output for any kind of modeling application. As input it takes values for he explanatory variables in the model (`data`), the transformation functions used by the model (`transformations`), and the model parameters (`model`). It returns model predictions in probability ratio output (PRO) format for each location represented in `data`. PRO format represents _relative_ probability of presence, and is a simple linear rescaling of raw Maxent output format such that PRO = 1 can be used as a reference value.

>__A value of PRO = 1 can be interpreted as the expected relative probability of a cell randomly drawn from the study area. Put another way, cells with PRO > 1 have a greater relative probability of presence than an "average" cell in the study area.__

Here, we obtain model output across the extent of the study area as represented by the training data (note again that `model` and `transformation` file pathways will normally lead to files in the user-specified directory):
```{r}
grasslandPrediction <- projectModel(grasslandPO, 
    transformation = grasslandDVs[[2]], 
    model = system.file("extdata", "1.lambdas", package = "maxentmodelselectr"))
```

Model predictions are appended to the `data` in column 1:
```{r}
head(grasslandPrediction$output)
```

Additionally, the `projectModel` function automatically checks how the range of the input explanatory data compares to the range of the data used to train the model. This is important because if the range of the input data lies outside the range of the training data (called model extrapolation), the model is less reliable. The range of continuous variables is reported on the training data scale, from 0 to 1, and the range of categorical variables is reported as "inside" if all categories are represented in the training data:
```{r}
grasslandPrediction$ranges
```
Since we projected the model over the training data, it makes sense that all the ranges are reported as [0,1] or "inside".

Note that `MIAmaxent` never uses any location data in the modelling process -- Maxent distribution modelling is not spatially explicit. Therefore, if model predictions are to be used in a spatial context (mapped), it can be helpful to include spatial coordinates in the `data` input to the `projectModel`. Here is some code (using the `raster` package again) that shows an example of how to plot model predictions spatially:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.cap="Model predictions in probability ratio output (PRO) across the study area"}
contfiles <- list.files(system.file("extdata", "EV_continuous", package = "maxentmodelselectr"), full.names = TRUE)
catfiles <- list.files(system.file("extdata", "EV_categorical", package = "maxentmodelselectr"), full.names = TRUE)
stack <- raster::stack(c(contfiles, catfiles))
stackpts <- rasterToPoints(stack)
spatialPrediction <- projectModel(stackpts, 
  transformation = grasslandDVs[[2]], 
  model = system.file("extdata", "1.lambdas", package = "maxentmodelselectr"))
Predictionraster <- raster(stack, layer=0)
Predictionraster <- rasterize(spatialPrediction$output[, c("x", "y")], Predictionraster, field = spatialPrediction$output$PRO)
plot(Predictionraster, colNA="black")
```


***


## Evaluating the model
There are many ways of evaluating the quality of a model, including assessing the explanatory variables selected and gauging the realism of response curves. Arguably the best way to evaluate a model, however, is to test how often its predictions are correct using occurrence data which are independent from the data used to train the model. This gives a precise metric of model accuracy, and ensures that the model success is not the result of peculiarities of the training data (such as sampling bias). Independent, presence-absence test data are not always available, for example when projecting a model into the future, but when they are, they represent a gold standard in model evaluation.

##### testAUC(...)

The evaluation metric which is used most commonly for distribution models and is implemented in `MIAmaxent` is Area Under the Curve (AUC) of the receiver operating characteristic. This is a metric which measures the performance of the model as a binary classifier over the full range of discrimination thresholds. When calculated using the training data `MIAmaxent` refers to it as "trainAUC" (for example in the forward selection trails), and when it is calculated using independent test data it is referred to as "testAUC".

The `testAUC` function takes a data frame of presence or absence locations, along with the corresponding values of explanatory variable at those locations, and calculates a testAUC value for the model. The presence-absence occurrence data can be read into R using the `readData` function with `PA = TRUE` if desired.

In our example, 122 test locations in Ã˜sfold County, Norway, were visited to record presence or absence of semi-natural grasslands. Plotted on the raster of model predictions these data look like this:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.cap="Presence (red) and absence (blue) test data plotted over model predictions"}
grasslandPA <- readData(occurrence = system.file("extdata", "occurrence_PA.csv", package = "maxentmodelselectr"), 
  contEV = system.file("extdata", "EV_continuous", package = "maxentmodelselectr"),
  catEV = system.file("extdata", "EV_categorical", package = "maxentmodelselectr"),
  PA = TRUE, XY = TRUE)
head(grasslandPA)
tail(grasslandPA)

plot(Predictionraster, colNA="black")
presences <- grasslandPA[grasslandPA$RV==1, ]
absences <- grasslandPA[grasslandPA$RV==0, ]
points(presences$x, presences$y, pch = 20, cex = 0.5, col = 'red')
points(absences$x, absences$y, pch = 20, cex = 0.5, col = 'blue')
```

We can use these data to calculate testAUC for our distribution model:
```{r, fig.show='hold', fig.width=5, fig.height=5, fig.align = "center"}
grasslandAUC <- testAUC(grasslandPA, 
  transformation = grasslandDVs[[2]], 
  model = system.file("extdata", "1.lambdas", package = "maxentmodelselectr"))
grasslandAUC
```

The ROC plot produced by `testAUC` shows how the rate of true positives as well as false positives increases as the binary classification threshold is lowered. The area under this curve corresponds to the value of testAUC.  


***


## References

[^1]: Halvorsen, R. (2013) A strict maximum likelihood explanation of MaxEnt, and some implications for distribution modelling. Sommerfeltia, 36, 1-132.
[^2]: Halvorsen, R., Mazzoni, S., Bryn, A. & Bakkestuen, V. (2015) Opportunities for improved distribution modelling practice via a strict maximum likelihood interpretation of MaxEnt. Ecography, 38, 172-183.
